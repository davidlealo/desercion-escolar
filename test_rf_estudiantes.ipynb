{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v5/8__wxdkj3j713bygpr1tsw_80000gn/T/ipykernel_88741/3969867569.py:1: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  m2018 = pd.read_csv('data/matriculas/2018/m2018.csv', sep=';')\n",
      "/var/folders/v5/8__wxdkj3j713bygpr1tsw_80000gn/T/ipykernel_88741/3969867569.py:2: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  m2019 = pd.read_csv('data/matriculas/2019/m2019.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "m2018 = pd.read_csv('data/matriculas/2018/m2018.csv', sep=';')\n",
    "m2019 = pd.read_csv('data/matriculas/2019/m2019.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analisis import estudiantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlealolivares/Library/Mobile Documents/com~apple~CloudDocs/Talleres y ayudantias Diplomado DataScience UC2023/desercion-escolar/analisis.py:123: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  desertores = desertores[~((desertores['COD_GRADO'] == 4) & (df_anterior['COD_ENSE2'].isin([5, 7])))]\n"
     ]
    }
   ],
   "source": [
    "estudiantes2018 = estudiantes(m2018, m2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar estudiantes 2018\n",
    "estudiantes2018 = pd.read_csv('data/tablas/estudiantes2018.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79503 entries, 0 to 79502\n",
      "Data columns (total 36 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      79503 non-null  int64 \n",
      " 1   AGNO            79503 non-null  int64 \n",
      " 2   RBD             79503 non-null  int64 \n",
      " 3   DGV_RBD         79503 non-null  int64 \n",
      " 4   NOM_RBD         79503 non-null  object\n",
      " 5   COD_REG_RBD     79503 non-null  int64 \n",
      " 6   COD_PRO_RBD     79503 non-null  int64 \n",
      " 7   COD_COM_RBD     79503 non-null  int64 \n",
      " 8   NOM_COM_RBD     79503 non-null  object\n",
      " 9   COD_DEPROV_RBD  79503 non-null  int64 \n",
      " 10  NOM_DEPROV_RBD  79503 non-null  object\n",
      " 11  COD_DEPE        79503 non-null  int64 \n",
      " 12  COD_DEPE2       79503 non-null  int64 \n",
      " 13  RURAL_RBD       79503 non-null  int64 \n",
      " 14  ESTADO_ESTAB    79503 non-null  int64 \n",
      " 15  COD_ENSE        79503 non-null  int64 \n",
      " 16  COD_ENSE2       79503 non-null  int64 \n",
      " 17  COD_ENSE3       79503 non-null  int64 \n",
      " 18  COD_GRADO       79503 non-null  int64 \n",
      " 19  COD_GRADO2      79503 non-null  int64 \n",
      " 20  LET_CUR         79503 non-null  object\n",
      " 21  COD_JOR         79503 non-null  int64 \n",
      " 22  COD_TIP_CUR     79503 non-null  int64 \n",
      " 23  COD_DES_CUR     79503 non-null  int64 \n",
      " 24  MRUN            79503 non-null  int64 \n",
      " 25  GEN_ALU         79503 non-null  int64 \n",
      " 26  FEC_NAC_ALU     79503 non-null  int64 \n",
      " 27  EDAD_ALU        79503 non-null  int64 \n",
      " 28  COD_REG_ALU     79503 non-null  int64 \n",
      " 29  COD_COM_ALU     79503 non-null  int64 \n",
      " 30  NOM_COM_ALU     79503 non-null  object\n",
      " 31  COD_SEC         79503 non-null  int64 \n",
      " 32  COD_ESPE        79503 non-null  int64 \n",
      " 33  COD_RAMA        79503 non-null  int64 \n",
      " 34  ENS             79503 non-null  int64 \n",
      " 35  DESERTOR        79503 non-null  int64 \n",
      "dtypes: int64(31), object(5)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "estudiantes2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop COD_PRO_RBD, NOM_COM_RBD, COD_DEPROV_RBD, NOM_DEPROV_RBD\n",
    "estudiantes2018.drop(['COD_PRO_RBD', 'NOM_COM_RBD', 'COD_DEPROV_RBD', 'NOM_DEPROV_RBD'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar Unnamed\n",
    "estudiantes2018 = estudiantes2018.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar AGNO, FEC_NAC_ALU de d2018\n",
    "estudiantes2018 = estudiantes2018.drop(['AGNO', 'FEC_NAC_ALU'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NOM_COM_ALU, NOM_RBD y LET_CUR\n",
    "estudiantes2018.drop(['NOM_RBD', 'NOM_COM_ALU', 'LET_CUR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir x e y\n",
    "x = estudiantes2018.drop(['DESERTOR'], axis=1)\n",
    "y = estudiantes2018['DESERTOR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test 80-20, stratify y random_state=2023\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar las columnas categóricas\n",
    "categorical_cols = x_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Realizar la codificación one-hot\n",
    "x_train_encoded = pd.get_dummies(x_train, columns=categorical_cols)\n",
    "x_test_encoded = pd.get_dummies(x_test, columns=categorical_cols)\n",
    "\n",
    "# Entrenar el modelo con los datos codificados\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Predecir con los datos codificados\n",
    "y_pred = rf_model.predict(x_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluamos\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     15901\n",
      "\n",
      "    accuracy                           1.00     15901\n",
      "   macro avg       1.00      1.00      1.00     15901\n",
      "weighted avg       1.00      1.00      1.00     15901\n",
      "\n",
      "Matriz de confusión\n",
      "[[15901]]\n",
      "Variable: RBD                  Importancia: 0.0\n",
      "Variable: DGV_RBD              Importancia: 0.0\n",
      "Variable: COD_REG_RBD          Importancia: 0.0\n",
      "Variable: COD_COM_RBD          Importancia: 0.0\n",
      "Variable: COD_DEPE             Importancia: 0.0\n",
      "Variable: COD_DEPE2            Importancia: 0.0\n",
      "Variable: RURAL_RBD            Importancia: 0.0\n",
      "Variable: ESTADO_ESTAB         Importancia: 0.0\n",
      "Variable: COD_ENSE             Importancia: 0.0\n",
      "Variable: COD_ENSE2            Importancia: 0.0\n",
      "Variable: COD_ENSE3            Importancia: 0.0\n",
      "Variable: COD_GRADO            Importancia: 0.0\n",
      "Variable: COD_GRADO2           Importancia: 0.0\n",
      "Variable: COD_JOR              Importancia: 0.0\n",
      "Variable: COD_TIP_CUR          Importancia: 0.0\n",
      "Variable: COD_DES_CUR          Importancia: 0.0\n",
      "Variable: MRUN                 Importancia: 0.0\n",
      "Variable: GEN_ALU              Importancia: 0.0\n",
      "Variable: EDAD_ALU             Importancia: 0.0\n",
      "Variable: COD_REG_ALU          Importancia: 0.0\n",
      "Variable: COD_COM_ALU          Importancia: 0.0\n",
      "Variable: COD_SEC              Importancia: 0.0\n",
      "Variable: COD_ESPE             Importancia: 0.0\n",
      "Variable: COD_RAMA             Importancia: 0.0\n",
      "Variable: ENS                  Importancia: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el random forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Evaluamos\n",
    "print('Evaluamos')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "print('Matriz de confusión')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Importancia de las variables\n",
    "importances = list(rf_model.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(x_train.columns, importances)]\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "[print('Variable: {:20} Importancia: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Guardar modelo\n",
    "import pickle\n",
    "pickle.dump(rf_model, open('data/modelos/rf_model.pkl', 'wb'))\n",
    "\n",
    "# Cargar modelo\n",
    "# rf_model = pickle.load(open('data/modelos/rf_model.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los hiperparámetros\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 15, 20]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Crear el diccionario con los hiperparámetros\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Instanciar el grid search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=hyperparameter_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Entrenar el grid search\n",
    "grid_search.fit(x_train_encoded, y_train)\n",
    "\n",
    "# Mejores hiperparámetros\n",
    "grid_search.best_params_\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predecir con el mejor modelo\n",
    "y_pred = best_model.predict(x_test_encoded)\n",
    "\n",
    "# Evaluamos\n",
    "print('Evaluamos')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "print('Matriz de confusión')\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "# Importancia de las variables\n",
    "importances = list(best_model.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(x_train.columns, importances)]\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "[print('Variable: {:20} Importancia: {}'.format(*pair)) for pair in feature_importances]\n",
    "\n",
    "# Guardar modelo\n",
    "pickle.dump(best_model, open('data/modelos/best_model_rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_object = shap.TreeExplainer(best_model)\n",
    "shapley_values = explainer_object.shap_values(x_train_encoded)\n",
    "\n",
    "i = 1\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_object.expected_value, shapley_values[i], features=x_train_encoded.loc[i], feature_names=x_train_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "shap.force_plot(explainer_object.expected_value, shapley_values[i], features=x_train_encoded.loc[i], feature_names=x_train_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer_object(x_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = shap.Explainer(best_model, x_train_encoded)\n",
    "shap_values = exp(x_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shapley_values, features=x_train_encoded, feature_names=x_train_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(x_train),\n",
    "    feature_names=x_train.columns,\n",
    "    class_names=[0, 1],\n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=12\n",
    "\n",
    "exp_rf = explainer.explain_instance(\n",
    "    data_row = test_X.iloc[i], \n",
    "    predict_fn = best_model.predict_proba\n",
    ")\n",
    "\n",
    "exp_rf.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluamos\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     15901\n",
      "\n",
      "    accuracy                           1.00     15901\n",
      "   macro avg       1.00      1.00      1.00     15901\n",
      "weighted avg       1.00      1.00      1.00     15901\n",
      "\n",
      "Matriz de confusión\n",
      "[[15901]]\n"
     ]
    }
   ],
   "source": [
    "# mlp_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes= (150,120,100,50),\n",
    "                          activation='relu',\n",
    "                          max_iter= 100,\n",
    "                          solver='sgd',\n",
    "                          random_state=2023)\n",
    "mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos\n",
    "y_pred = mlp_model.predict(x_test)\n",
    "\n",
    "# Evaluamos\n",
    "print('Evaluamos')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "print('Matriz de confusión')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Guardar modelo\n",
    "pickle.dump(mlp_model, open('data/modelos/mlp_model.pkl', 'wb'))\n",
    "\n",
    "# Cargar modelo\n",
    "# mlp_model = pickle.load(open('data/modelos/mlp_model.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
